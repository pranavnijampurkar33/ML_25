{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d362591e-9f54-46f9-b703-49062ac3072f",
   "metadata": {},
   "source": [
    "# Knowledge Graph RAG\n",
    "\n",
    "<img src=\"./media/graph_start.png\" width=600>\n",
    "\n",
    "*[Improving Knowledge Graph Completion with Generative LM and neighbors](https://deeppavlov.ai/research/tpost/bn15u1y4v1-improving-knowledge-graph-completion-wit)*\n",
    "\n",
    "In the evolving landscape of AI and information retrieval, knowledge graphs have emerged as a powerful way to represent complex, interconnected information. A knowledge graph is a knowledge base that uses a graph-structured data model or topology to represent and operate on data. Knowledge graphs are often used to store interlinked descriptions of entities – objects, events, situations or abstract concepts – while also encoding the free-form semantics or relationships underlying these entities. [Source: Wikipedia](https://en.wikipedia.org/wiki/Knowledge_graph)\n",
    "\n",
    "What makes knowledge graphs particularly powerful is their ability to mirror human cognition in data. They more explicitly map the relationships between objects, concepts, or ideas together through both their semantic and relational connections. This approach closely parallels how our brains naturally understand and internalize information – not as isolated facts, but as a web of interconnected concepts and relationships.\n",
    "\n",
    "<img src=\"./media/coffee_graph_ex.png\" width=400>\n",
    "\n",
    "Looking at a concept like \"coffee,\" we don't just know it's a beverage; we automatically connect it to related concepts like beans, brewing methods, caffeine, morning routines, and social interactions. Knowledge graphs capture these natural associations in a structured way.\n",
    "\n",
    "Traditional RAG systems, while effective at semantic similarity-based retrieval, often struggle to capture broader conceptual relationships across text chunks. Knowledge Graph RAG addresses this limitation by introducing a structured, hierarchical approach to information organization and retrieval. By representing data in a graph format, these systems can traverse relationships between concepts, enabling more sophisticated query understanding and response generation. This approach allows for targeted querying along specific relationship paths, handles complex multi-hop questions, and provides clearer reasoning through explicit connection paths. The result is a more nuanced and interpretable system that combines the structured reasoning of knowledge graphs with the natural language capabilities of large language models.\n",
    "\n",
    "While [knowledge graphs are not a new concept](https://blog.google/products/search/introducing-knowledge-graph-things-not/), their creation has traditionally been a resource-intensive process. Early knowledge graphs were built either through manual curation by domain experts or by converting existing structured data from relational databases. This limited both their scale and adaptability to new domains.\n",
    "\n",
    "<img src=\"./media/table_comp.png\" width=600>\n",
    "\n",
    "*[What is a Knowledge Graph (KG)?](https://zilliz.com/learn/what-is-knowledge-graph)*\n",
    "\n",
    "The introduction of LLMs has transformed this landscape. LLMs' capabilities in NLP, reasoning, and relationship extraction now enable automated construction of knowledge graphs from unstructured text. These models can identify entities, infer relationships, and structure information in ways that previously required extensive manual labor. As a plus, this allows knowledge graphs to be dynamically updated and expanded as new information becomes available, making them more practical and scalable for real-world applications.\n",
    "\n",
    "To see this in action ourselves, and compare it to traditional vector similarity techniques, we'll take a look at Microsoft's Open Source [GraphRAG](https://microsoft.github.io/graphrag/) and how it works behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb752dad-d6bf-436f-a175-03a1d491bb3e",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Main Components of Knowledge Graphs\n",
    "\n",
    "**Entity**\n",
    "\n",
    "<img src=\"./media/entities.png\" width=500>\n",
    "\n",
    "An Entity is a distinct object, person, place, event, or concept that has been extracted from a chunk of text through LLM analysis. Entities form the nodes of the knowledge graph. During the creation of the knowledge graph, when duplicate entities are found they are merged while preserving their various descriptions, creating a comprehensive representation of each unique entity.\n",
    "\n",
    "**Relationship**\n",
    "\n",
    "<img src=\"./media/relationship.png\" width=400>\n",
    "\n",
    "A Relationship defines a connection between two entities in the knowledge graph. These connections are extracted directly from text units through LLM analysis, alongside entities. Each relationship includes a source entity, target entity, and descriptive information about their connection. When duplicate relationships are found between the same entities, they are merged by combining their descriptions to create a more complete understanding of the connection.\n",
    "\n",
    "**Community**\n",
    "\n",
    "<img src=\"./media/communities.png\" width=400>\n",
    "\n",
    "A Community is a cluster of related entities and relationships identified through hierarchical community detection, generally using the [Leiden Algorithm](https://en.wikipedia.org/wiki/Leiden_algorithm). Communities create a structured way to understand different levels of granularity within the knowledge graph, from broad overviews at the top level to detailed local clusters at lower levels. This hierarchical structure helps in organizing and navigating complex knowledge graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7e77f-a543-49e2-813e-c1305f7a058d",
   "metadata": {},
   "source": [
    "---\n",
    "## GraphRAG Creation Data Flow\n",
    "\n",
    "<img src=./media/graph_building.png width=1000>\n",
    "\n",
    "Indexxing in GraphRAG is an extensive process, where we load the document, split it into chunks, create sub graphs at a chunk level, combine these subgraphs into our final graph, algorithmically identify communities, then document the communities main features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19896a38-bcf7-4664-9f57-cb12cf15cdea",
   "metadata": {},
   "source": [
    "### **Loading and Splitting Our Text**\n",
    "\n",
    "For our example, we'll be using [The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities](https://arxiv.org/pdf/2408.13296).\n",
    "\n",
    "This will be loaded as a text file (remove index, glossary, and references) and split into 1200 token, 100 token overlap chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e6a581-74a1-455e-8634-2c94d6496e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "with open(\"./input/ft_guide.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=1200, chunk_overlap=100)\n",
    "\n",
    "texts = text_splitter.split_text(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9e65e-531c-4e94-9808-4ede865621d7",
   "metadata": {},
   "source": [
    "**Entity and Relationship Extraction Prompt**\n",
    "\n",
    "This is a [tuned](https://microsoft.github.io/graphrag/prompt_tuning/auto_prompt_tuning/) entity extraction prompt used in our real GraphRAG implementation, extracted in this format to see what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6236c47-8584-41d6-8553-f516e282d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o\", openai_api_key=openai_api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "-Goal-\n",
    "Given a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: One of the following types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\"{{tuple_delimiter}}<entity_name>{{tuple_delimiter}}<entity_type>{{tuple_delimiter}}<entity_description>)\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "- relationship_strength: an integer score between 1 to 10, indicating strength of the relationship between the source entity and target entity\n",
    "Format each relationship as (\"relationship\"{{tuple_delimiter}}<source_entity>{{tuple_delimiter}}<target_entity>{{tuple_delimiter}}<relationship_description>{{tuple_delimiter}}<relationship_strength>)\n",
    "\n",
    "3. Return output in The primary language of the provided text is \"English.\" as a single list of all the entities and relationships identified in steps 1 and 2. Use **{{record_delimiter}}** as the list delimiter.\n",
    "\n",
    "4. If you have to translate into The primary language of the provided text is \"English.\", just translate the descriptions, nothing else!\n",
    "\n",
    "5. When finished, output {{completion_delimiter}}.\n",
    "\n",
    "-Examples-\n",
    "######################\n",
    "\n",
    "Example 1:\n",
    "\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text:\n",
    " LLMs to create synthetic samples that mimic clients’ private data distribution using\n",
    "differential privacy. This approach significantly boosts SLMs’ performance by approximately 5% while\n",
    "maintaining data privacy with a minimal privacy budget, outperforming traditional methods relying\n",
    "solely on local private data.\n",
    "In healthcare, federated fine-tuning can allow hospitals to collaboratively train models on patient data\n",
    "without transferring sensitive information. This approach ensures data privacy while enabling the de-\n",
    "velopment of robust, generalisable AI systems.\n",
    "8https://ai.meta.com/responsible-ai/\n",
    "9https://huggingface.co/docs/hub/en/model-cards\n",
    "10https://www.tensorflow.org/responsible_ai/privacy/guide\n",
    "101 Frameworks for Enhancing Security\n",
    "Adversarial training and robust security measures[111] are essential for protecting fine-tuned models\n",
    "against attacks. The adversarial training approach involves training models with adversarial examples\n",
    "to improve their resilience against malicious inputs. Microsoft Azure’s\n",
    "------------------------\n",
    "output:\n",
    "(\"entity\"{{tuple_delimiter}}DIFFERENTIAL PRIVACY{{tuple_delimiter}}differential privacy{{tuple_delimiter}}Differential privacy is a technique used to create synthetic samples that mimic clients' private data distribution while maintaining data privacy with a minimal privacy budget{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}HEALTHCARE{{tuple_delimiter}}healthcare{{tuple_delimiter}}In healthcare, federated fine-tuning allows hospitals to collaboratively train models on patient data without transferring sensitive information, ensuring data privacy{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}federated learning{{tuple_delimiter}}Federated learning is a method that enables collaborative model training on decentralized data sources, such as hospitals, without sharing sensitive information{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}ADVERSARIAL TRAINING{{tuple_delimiter}}adversarial training{{tuple_delimiter}}Adversarial training involves training models with adversarial examples to improve their resilience against malicious inputs{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}SECURITY MEASURES{{tuple_delimiter}}security measures{{tuple_delimiter}}Robust security measures are essential for protecting fine-tuned models against attacks{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}DIFFERENTIAL PRIVACY{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}Differential privacy is used in federated learning to maintain data privacy while training models collaboratively{{tuple_delimiter}}8{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}HEALTHCARE{{tuple_delimiter}}FEDERATED LEARNING{{tuple_delimiter}}Federated learning is applied in healthcare to train models on patient data without transferring sensitive information{{tuple_delimiter}}9{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ADVERSARIAL TRAINING{{tuple_delimiter}}SECURITY MEASURES{{tuple_delimiter}}Adversarial training is a security measure used to protect models against attacks by improving their resilience{{tuple_delimiter}}8{{completion_delimiter}}\n",
    "#############################\n",
    "\n",
    "\n",
    "Example 2:\n",
    "\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text:\n",
    "ARD [82] is an innovative open-source tool developed to enhance the safety of interactions\n",
    "with large language models (LLMs). This tool addresses three critical moderation tasks: detecting\n",
    "2https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForCausalLM\n",
    "63 harmful intent in user prompts, identifying safety risks in model responses, and determining when a\n",
    "model appropriately refuses unsafe requests. Central to its development is WILDGUARD MIX3, a\n",
    "meticulously curated dataset comprising 92,000 labelled examples that include both benign prompts and\n",
    "adversarial attempts to bypass safety measures. The dataset is divided into WILDGUARD TRAIN, used\n",
    "for training the model, and WILDGUARD TEST, consisting of high-quality human-annotated examples\n",
    "for evaluation.\n",
    "The WILDGUARD model itself is fine-tuned on the Mistral-7B language model using the WILDGUARD\n",
    "TRAIN dataset, enabling it to perform all\n",
    "------------------------\n",
    "output:\n",
    "```plaintext\n",
    "(\"entity\"{{tuple_delimiter}}ARD{{tuple_delimiter}}open-source tool{{tuple_delimiter}}ARD is an innovative open-source tool developed to enhance the safety of interactions with large language models by addressing moderation tasks such as detecting harmful intent, identifying safety risks, and determining appropriate refusals of unsafe requests)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}LARGE LANGUAGE MODELS{{tuple_delimiter}}large language model{{tuple_delimiter}}Large language models (LLMs) are advanced AI models designed to understand and generate human-like text, which ARD aims to interact with safely)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD MIX3 is a meticulously curated dataset comprising 92,000 labeled examples, including benign prompts and adversarial attempts, used for training and evaluating safety measures in language models)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD TRAIN is a subset of the WILDGUARD MIX3 dataset used specifically for training the model on safety measures)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}WILDGUARD TEST{{tuple_delimiter}}dataset{{tuple_delimiter}}WILDGUARD TEST is a subset of the WILDGUARD MIX3 dataset consisting of high-quality human-annotated examples used for evaluating the model's performance)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}MISTRAL-7B{{tuple_delimiter}}large language model{{tuple_delimiter}}Mistral-7B is a language model that the WILDGUARD model is fine-tuned on using the WILDGUARD TRAIN dataset to enhance its safety performance)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}ADVERSARIAL ATTEMPTS{{tuple_delimiter}}adversarial training{{tuple_delimiter}}Adversarial attempts are part of the WILDGUARD MIX3 dataset, used to test and improve the model's ability to handle unsafe or harmful inputs)\n",
    "{{record_delimiter}}\n",
    "(\"entity\"{{tuple_delimiter}}SAFETY MEASURES{{tuple_delimiter}}security measures{{tuple_delimiter}}Safety measures are protocols and techniques implemented to ensure that large language models interact safely with users, which ARD and the WILDGUARD dataset aim to enhance)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ARD{{tuple_delimiter}}LARGE LANGUAGE MODELS{{tuple_delimiter}}ARD is designed to enhance the safety of interactions with large language models by addressing critical moderation tasks{{tuple_delimiter}}8)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ARD{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}ARD uses the WILDGUARD MIX3 dataset to train and evaluate its moderation capabilities{{tuple_delimiter}}7)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}WILDGUARD TRAIN is a subset of the WILDGUARD MIX3 dataset used for training{{tuple_delimiter}}9)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD MIX3{{tuple_delimiter}}WILDGUARD TEST{{tuple_delimiter}}WILDGUARD TEST is a subset of the WILDGUARD MIX3 dataset used for evaluation{{tuple_delimiter}}9)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}WILDGUARD TRAIN{{tuple_delimiter}}MISTRAL-7B{{tuple_delimiter}}The WILDGUARD TRAIN dataset is used to fine-tune the Mistral-7B language model{{tuple_delimiter}}8)\n",
    "{{record_delimiter}}\n",
    "(\"relationship\"{{tuple_delimiter}}ADVERSARIAL ATTEMPTS{{tuple_delimiter}}SAFETY MEASURES{{tuple_delimiter}}Adversarial attempts are used to test and improve safety measures in language models{{tuple_delimiter}}7)\n",
    "{{completion_delimiter}}\n",
    "```\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "entity_types: [large language model, differential privacy, federated learning, healthcare, adversarial training, security measures, open-source tool, dataset, learning rate, AdaGrad, RMSprop, adapter architecture, LoRA, API, model support, evaluation metrics, deployment, Python library, hardware accelerators, hyperparameters, data preprocessing, data imbalance, GPU-based deployment, distributed inference]\n",
    "text: {input_text}\n",
    "######################\n",
    "output:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0742c48f-043a-4653-ae9a-550d0b929386",
   "metadata": {},
   "source": [
    "**Creating a Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81a8e812-85b4-446b-9e54-ca8a227947f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input_text\": texts[25]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1176f935-4ffb-4e37-8daa-505edced7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd5fa6-626b-4c6b-ad17-84d4d3bc5bf4",
   "metadata": {},
   "source": [
    "We see the extraction of **entities**:\n",
    "\n",
    "`(\"entity\"{tuple_delimiter}EVALUATION METRICS{tuple_delimiter}evaluation metrics{tuple_delimiter}Evaluation metrics are criteria  used to assess the performance of AI models, including metrics like cross-entropy, perplexity, factuality, and context relevance)`\n",
    "\n",
    "As well as **relationships**:\n",
    "\n",
    "`(\"relationship\"{tuple_delimiter}EVALUATION METRICS{tuple_delimiter}CONTEXT RELEVANCE{tuple_delimiter}Context relevance is an evaluation metric that ensures the model uses the most pertinent information for generating responses{tuple_delimiter}8)`\n",
    "\n",
    "Following this, these per chunk subgraphs are merged together - any entities with the same name and type are merged by creating an array of their descriptions. Similarly, any relationships with the same source and target are merged by creating an array of their descriptions. These lists are then summarized one more time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad41d036-00da-4dba-8fcf-1cee5b683d52",
   "metadata": {},
   "source": [
    "### **Looking at Final Entities and Relationships**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d392cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26613855-7891-4b16-ad84-758f8a0ed8fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'create_final_entities.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m entities \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreate_final_entities.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m entities\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniconda3/envs/docai/lib/python3.10/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/docai/lib/python3.10/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/docai/lib/python3.10/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/docai/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'create_final_entities.parquet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entities = pd.read_parquet('create_final_entities.parquet')\n",
    "\n",
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4bf9fc-bb4e-4546-897b-991236079323",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = pd.read_parquet('./ragtest/output/create_final_relationships.parquet')\n",
    "\n",
    "relationships.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c77836-f9ae-4602-a4d0-760915248e0a",
   "metadata": {},
   "source": [
    "### **Community Detection & Node Embedding**\n",
    "\n",
    "<img src=\"./media/leidan.png\" width=600>\n",
    "\n",
    "After we have our basic graph with entities and relationships, we analyze its structure in two ways. Community Detection uses the [Leiden algorithm](https://en.wikipedia.org/wiki/Leiden_algorithm) to find explicit groupings in the graph, creating a hierarchy of related entities. The lower in the hierarchy, the more granular the community. Node Embedding uses [Node2Vec](https://arxiv.org/abs/1607.00653) to create vector representations of each entity, capturing implicit relationships in the graph structure. These complementary approaches let us understand both obvious connections through communities and subtle patterns through embeddings.\n",
    "\n",
    "Combining all of this with our relationships gives us our final nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d8f6d-6eb7-45fe-bf1c-e28055a683c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_parquet('./ragtest/output/create_final_nodes.parquet')\n",
    "\n",
    "nodes.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b12c9-fc5c-47cf-a597-6c6bfb3177ee",
   "metadata": {},
   "source": [
    "At this step the graph is effectively created, however we can introduce a few extra steps that will allow us to do some advanced retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8ed95-677b-405e-82d3-6fb1a3f1917c",
   "metadata": {},
   "source": [
    "### Community Report Generation & Summarization\n",
    "\n",
    "Now that we have clear community grouping, we can aggregate the main concepts across hierarchical node communities with another generation step, and a shorthand summary of that summary. Similar to the nodes, these summaries are also ran through an embedding model and stored in a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e5559-ed4e-4964-bf72-113912974102",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_reports = pd.read_parquet('./ragtest/output/create_final_community_reports.parquet')\n",
    "\n",
    "community_reports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca51c33-92db-47c1-9f00-0a8e934332fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(community_reports[\"full_content\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3e76b-e59f-4577-b1a0-3b07f0ebb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(community_reports[\"summary\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5243d1-e1d2-4525-ab3c-e1457db2eea7",
   "metadata": {},
   "source": [
    "### The Final Graph!\n",
    "\n",
    "<img src=\"./media/ghraphrag_viz.svg\" width=800>\n",
    "\n",
    "*[Full Size PDF](./ghraphrag_viz.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172bf775-ee3b-4d4a-a973-317f1681b8af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GraphRAG Retrieval\n",
    "\n",
    "<img src=\"./media/kg_retrieval.png\" width=600>\n",
    "\n",
    "*[Unifying Large Language Models and Knowledge Graphs: A Roadmap](https://arxiv.org/pdf/2306.08302)*\n",
    "\n",
    "With our knowledge graph constructed, and hierarchichal communities delineated, we can now perform multiple types of search that can both take advantage of the graph structure, and multiple levels of specificity across our communities. Specifically:\n",
    "\n",
    "1. **Global Search**: Uses the LLM Generated community reports from a specified level of the graph's community hierarchy as context data to generate response.\n",
    "2. **Local Search**: Combines structured data from the knowledge graph with unstructured data from the input document(s) to augment the LLM context with relevant entity information.\n",
    "3. **Drift Search**: Dynamic Reasoning and Inference with Flexible Traversal, an approach to local search queries by including community information in the search process, thus combining global and local search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a5823-048b-4a54-9da5-51305b8a1c7a",
   "metadata": {},
   "source": [
    "**GraphRAG Retrieval Function**\n",
    "\n",
    "*Note: Wrapping the [GraphRAG CLI tool](https://microsoft.github.io/graphrag/cli/) as a function here instead of using their [library](https://microsoft.github.io/graphrag/examples_notebooks/api_overview/) for an easier example. As such, notebook needs to be running in the same GraphRAG environment/kernal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ae01778e-518f-42fe-929e-dd2ef63a8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shlex\n",
    "from typing import Optional\n",
    "\n",
    "def query_graphrag(\n",
    "    query: str,\n",
    "    method: str = \"global\",\n",
    "    root_path: str = \"./ragtest\",\n",
    "    timeout: Optional[int] = None,\n",
    "    community_level: int = 2,\n",
    "    dynamic_community_selection: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Execute a GraphRAG query using the CLI tool.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query string to process\n",
    "        method (str): Query method (e.g., \"global\", \"local\", or \"drift\")\n",
    "        root_path (str): Path to the root directory\n",
    "        timeout (int, optional): Timeout in seconds for the command\n",
    "        community_level (int): The community level in the Leiden community hierarchy (default: 2)\n",
    "        dynamic_community_selection (bool): Whether to use global search with dynamic community selection (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        str: The output from GraphRAG\n",
    "        \n",
    "    Raises:\n",
    "        subprocess.CalledProcessError: If the command fails\n",
    "        subprocess.TimeoutExpired: If the command times out\n",
    "        ValueError: If community_level is negative\n",
    "    \"\"\"\n",
    "    # Validate community level\n",
    "    if community_level < 0:\n",
    "        raise ValueError(\"Community level must be non-negative\")\n",
    "    \n",
    "    # Construct the base command\n",
    "    command = [\n",
    "        'graphrag', 'query',\n",
    "        '--root', root_path,\n",
    "        '--method', method,\n",
    "        '--query', query,\n",
    "        '--community-level', str(community_level)\n",
    "    ]\n",
    "    \n",
    "    # Add dynamic community selection flag if enabled\n",
    "    if dynamic_community_selection:\n",
    "        command.append('--dynamic-community-selection')\n",
    "    \n",
    "    try:\n",
    "        # Execute the command and capture output\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        # Check if the command was successful\n",
    "        result.check_returncode()\n",
    "        \n",
    "        return result.stdout.strip()\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        error_message = f\"Command failed with exit code {e.returncode}\\nError: {e.stderr}\"\n",
    "        raise subprocess.CalledProcessError(\n",
    "            e.returncode,\n",
    "            e.cmd,\n",
    "            output=e.output,\n",
    "            stderr=error_message\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02da6ea-e0ad-41d4-982a-f9058184add0",
   "metadata": {},
   "source": [
    "### Local Search\n",
    "\n",
    "<img src=\"./media/local_search.png\" width=900>\n",
    "\n",
    "The GraphRAG approach to local search is the most similar to regular semantic RAG search. It combines structured data from the knowledge graph with unstructured data from the input documents to augment the LLM context with relevant entity information. In essence, we are going to first search for relevant entities to the query using semantic search. These become the entry points on our graph that we can now traverse. Starting at these points, we look at connected chunks of text, community reports, other entities, and relationships between them. All of the data retrieved is filtered and ranked to fit into a pre-defined context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad477f20-1019-4da6-a70a-9cc9e362fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_graphrag(\n",
    "    query=\"How does a company choose between RAG, fine-tuning, and different PEFT approaches?\",\n",
    "    method=\"local\"\n",
    ")\n",
    "print(\"Query result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8368cd-25bb-4460-802f-8ed76a39bb2d",
   "metadata": {},
   "source": [
    "### Global Search\n",
    "\n",
    "<img src=\"./media/global_search.png\" width=1000>\n",
    "\n",
    "Through the semantic clustering of communities during the indexxing process outlined above we created community reports as summaries of high level themes across these groupings. Having this community summary data at various levels allows us to do something that traditional RAG performs poorly at, answering queries about broad themes and ideas across our unstructured data.\n",
    "\n",
    "To capture as much broad information as possible in an efficient manner, GraphRAG implements a [map reduce](https://en.wikipedia.org/wiki/MapReduce) approach. Given a query, relevant community node reports at a specific hierarchical level are retrieved. These are shuffled and chunked, where each chunk is used to generate a list of points that each have their own \"importance score\". These intermediate points are ranked and filtered, attempting to maintain the most important points. These become the aggregate intermediary response, which is passed to the LLM as the context for the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b59560-c02f-4c2e-a969-8042caef03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_graphrag(\n",
    "    query=\"How does a company choose between RAG, fine-tuning, and different PEFT approaches?\",\n",
    "    method=\"global\"\n",
    ")\n",
    "print(\"Query result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d9948-ba7e-49af-ac49-62b835d62174",
   "metadata": {},
   "source": [
    "### DRIFT Search\n",
    "\n",
    "<img src=\"./media/drift_search.png\" width=1000>\n",
    "\n",
    "[Dynamic Reasoning and Inference with Flexible Traversal](https://www.microsoft.com/en-us/research/blog/introducing-drift-search-combining-global-and-local-search-methods-to-improve-quality-and-efficiency/), or DRIFT, is a novel GraphRAG concept introduced by Microsoft as an approach to local search queries that include community information in the search process.\n",
    "\n",
    "The user's query is initially processed through [Hypothetical Document Embedding (HyDE)](https://arxiv.org/pdf/2212.10496), which creates a hypothetical document similar to those found in the graph already, but using the user's topic query. This document is embedded and used for semantic retrieval of the top-k relevant community reports. From these matches, we generate an initial answer along with several follow-up questions as a lightweight version of global search. They refer to this as the primer.\n",
    "\n",
    "Once this primer phase is complete, we execute local searches for each follow-up question generated. Each local search produces both intermediate answers and new follow-up questions, creating a refinement loop. This loop runs for two iterations (noted future research planned to develop reward functions for smarter termination). An important note that makes these local searches unique is that they are informed by both community-level knowledge and detailed entity/relationship data. This allows the DRIFT process to find relevant information even when the initial query diverges from the indexing persona, and it can adapt its approach based on emerging information during the search.\n",
    "\n",
    "The final output is structured as a hierarchy of questions and answers, ranked by their relevance to the original query. Map reduce is used again with an equal weighting on all intermediate answers, then passed to the language model for a final response. DRIFT cleverly combines global and local search with guided exploration to provide both broad context and specific details in responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcac67-ab84-4dd7-bf7e-cf4b2a4e7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_graphrag(\n",
    "    query=\"How does a company choose between RAG, fine-tuning, and different PEFT approaches?\",\n",
    "    method=\"drift\"\n",
    ")\n",
    "print(\"Query result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e04a5-aa55-4955-b2c0-b86dd462f549",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comparing to Regular Vector Database Retrieval\n",
    "\n",
    "<img src=\"./media/basic_retrieval.png\" width=600>\n",
    " \n",
    "To give some comparison, let's look back at traditional chunking, embedding, and similarity retrieval RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12fa20-81d9-43cc-a641-6e8ba7cb5e9b",
   "metadata": {},
   "source": [
    "**Instantiate our Database**\n",
    "\n",
    "For this we'll be using [ChromaDB](https://www.trychroma.com) with the same chunks as were loaded into our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361a631-4e98-47d5-9b2d-48810c2eab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./notebook/chromadb\")\n",
    "paper_collection = chroma_client.get_or_create_collection(name=\"paper_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a160165-6ed9-4ac9-be3b-db5bff88beb4",
   "metadata": {},
   "source": [
    "**Embed Chunks Into Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24350f0f-32ef-41ea-9d7c-5e970ca172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for text in texts:\n",
    "    paper_collection.add(\n",
    "        documents=[text],\n",
    "        ids=f\"chunk_{i}\"\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3961f0-bdce-4d1d-8d49-86355bb7d505",
   "metadata": {},
   "source": [
    "**Retrieval Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f2276-fc27-4008-9e63-6ec9d4db66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_retrieval(query, num_results=5):\n",
    "    results = paper_collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=num_results\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2bb61e-5d36-47fc-b2ec-6557293f5ef4",
   "metadata": {},
   "source": [
    "**RAG Prompt & Chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "593a23ff-c34c-47b4-b6d8-c2ca59fad69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt_template = \"\"\"\n",
    "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
    "\n",
    "If you don't know the answer, just say so. Do not make anything up.\n",
    "\n",
    "Do not include information where the supporting evidence for it is not provided.\n",
    "\n",
    "Context: {retrieved_docs}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211bbff-9927-464b-942d-964005707475",
   "metadata": {},
   "source": [
    "**RAG Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e654479e-0d40-4de3-8d03-1de08b54a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_rag(query):\n",
    "    retrieved_docs = chroma_retrieval(query)[\"documents\"][0]\n",
    "    response = rag_chain.invoke({\"retrieved_docs\": retrieved_docs, \"query\": query})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba855e-b29c-4169-8302-b1b5cceee76c",
   "metadata": {},
   "source": [
    "**RAG Response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72201a27-6dac-4f3b-8ff9-717f4998470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chroma_rag(\"How does a company choose between RAG, fine-tuning, and different PEFT approaches?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6a630f-3268-45ec-b58f-dbb42106864a",
   "metadata": {},
   "source": [
    "---\n",
    "## Discussion\n",
    "\n",
    "**Traditional/Naive RAG:**\n",
    "\n",
    "Benefits:\n",
    "- Simpler implementation and deployment\n",
    "- Works well for straightforward information retrieval tasks\n",
    "- Good at handling unstructured text data\n",
    "- Lower computational overhead\n",
    "\n",
    "Drawbacks:\n",
    "- Loses structural information when chunking documents\n",
    "- Can break up related content during text segmentation\n",
    "- Limited ability to capture relationships between different pieces of information\n",
    "- May struggle with complex reasoning tasks requiring connecting multiple facts\n",
    "- Potential for incomplete or fragmented answers due to chunking boundaries\n",
    "\n",
    "**GraphRAG:**\n",
    "\n",
    "Benefits:\n",
    "- Preserves structural relationships and hierarchies in the knowledge\n",
    "- Better at capturing connections between related information\n",
    "- Can provide more complete and contextual answers\n",
    "- Improved retrieval accuracy by leveraging graph structure\n",
    "- Better supports complex reasoning across multiple facts\n",
    "- Can maintain document coherence better than chunk-based approaches\n",
    "- More interpretable due to explicit knowledge representation\n",
    "\n",
    "Drawbacks:\n",
    "- More complex to implement and maintain\n",
    "- Requires additional processing to construct and update knowledge graphs\n",
    "- Higher computational overhead for graph operations\n",
    "- May require domain expertise to define graph schema/structure\n",
    "- More challenging to scale to very large datasets\n",
    "- Additional storage requirements for graph structure\n",
    "\n",
    "**Key Differentiators:**\n",
    "1. Knowledge Representation: Traditional RAG treats everything as flat text chunks, while GraphRAG maintains structured relationships in a graph format\n",
    "\n",
    "2. Context Preservation: GraphRAG better preserves context and relationships between different pieces of information compared to the chunking approach of traditional RAG\n",
    "\n",
    "3. Reasoning Capability: GraphRAG enables better multi-hop reasoning and connection of related facts through graph traversal, while traditional RAG is more limited to direct retrieval\n",
    "\n",
    "4. Answer Quality: GraphRAG tends to produce more complete and coherent answers since it can access related information through graph connections rather than being limited by chunk boundaries\n",
    "\n",
    "The choice between traditional RAG and GraphRAG often depends on the specific use case, with GraphRAG being particularly valuable when maintaining relationships between information is important or when complex reasoning is required. An important note as well, GraphRAG approaches still rely on regular embedding and retrieval methods themselves. They compliment eahcother!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c5872-2185-46dc-aaef-2108bc490a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
